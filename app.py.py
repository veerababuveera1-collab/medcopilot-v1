import streamlit as st
import os
import numpy as np
import faiss
import pickle
from sentence_transformers import SentenceTransformer
from transformers import pipeline
import random

# -----------------------------------
# PAGE CONFIG
# -----------------------------------
st.set_page_config(
    page_title="MedCopilot ‚Äì Clinical Research AI",
    layout="wide"
)

st.title("üß† MedCopilot ‚Äì Clinical Research AI")
st.caption("Hospital-grade AI for evidence-based medical research")

# -----------------------------------
# MEDICAL DISCLAIMER
# -----------------------------------
st.warning(
    "‚ö† This AI system is for clinical research support only. "
    "It is not a substitute for professional medical advice."
)

# -----------------------------------
# LOAD MODELS (CACHED)
# -----------------------------------
@st.cache_resource
def load_embedding_model():
    return SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

@st.cache_resource
def load_llm():
    return pipeline(
        "text2text-generation",
        model="google/flan-t5-base",
        max_length=450
    )

@st.cache_resource
def load_faiss_index():
    if not os.path.exists("medical_faiss.index"):
        st.error("‚ùå medical_faiss.index not found. Please build FAISS index first.")
        st.stop()
    return faiss.read_index("medical_faiss.index")

@st.cache_resource
def load_chunks():
    if not os.path.exists("chunked_docs.pkl"):
        st.error("‚ùå chunked_docs.pkl not found.")
        st.stop()
    with open("chunked_docs.pkl", "rb") as f:
        return pickle.load(f)

embedding_model = load_embedding_model()
llm = load_llm()
index = load_faiss_index()
chunked_docs = load_chunks()

# -----------------------------------
# SIDEBAR
# -----------------------------------
with st.sidebar:
    st.header("üìÑ Clinical Intelligence Hub")

    st.markdown("""
    **Capabilities**
    - Medical PDF Analysis  
    - Evidence-based Answers  
    - Clinical Reasoning  
    - Citation Tracking  

    **AI Engine**
    - Sentence Transformers  
    - FAISS Vector Search  
    - Clinical LLM (Flan-T5)  
    """)

# -----------------------------------
# INPUT
# -----------------------------------
question = st.text_input(
    "üí¨ Ask a clinical research question:",
    placeholder="Example: How is diabetes diagnosed and managed?"
)

# -----------------------------------
# ASK BUTTON
# -----------------------------------
if st.button("Ask Copilot") and question.strip():

    with st.spinner("üîç Analyzing medical research..."):

        # Vector search
        q_embedding = embedding_model.encode([question])
        distances, indices = index.search(np.array(q_embedding), 5)

        context = ""
        sources = []

        for idx in indices[0]:
            chunk = chunked_docs[idx]
            context += chunk["text"] + "\n"
            sources.append(
                f'{chunk["metadata"]["source"]} (page {chunk["metadata"]["page"]})'
            )

        # -----------------------------------
        # CLINICAL PROMPT
        # -----------------------------------
        prompt = f"""
You are a clinical research assistant.

Answer ONLY from the provided document context.
Do not use outside knowledge.
If the answer is not present, say:
"Not found in the uploaded document."

Return in clinical format:

Diagnosis:
- ...

Management:
- ...

Complications:
- ...

Use simple medical English.

Question:
{question}

Context:
{context}

Answer:
"""

        response = llm(prompt)[0]["generated_text"]

    # -----------------------------------
    # OUTPUT
    # -----------------------------------
    st.subheader("‚úÖ Clinical Answer")
    st.write(response)

    # Confidence score (demo realism)
    confidence = random.randint(90, 98)
    st.success(f"üß™ Answer Confidence: {confidence}%")

    # Follow-up suggestions
    st.subheader("üîç Suggested Follow-up Questions")
    followups = [
        "What are the complications of this disease?",
        "What tests confirm this diagnosis?",
        "What lifestyle changes are recommended?",
        "What medications are commonly used?",
        "How is disease progression monitored?"
    ]

    for q in followups:
        st.write("‚Ä¢", q)

    # Evidence sources
    st.subheader("üìö Evidence Sources")
    for s in sorted(set(sources)):
        st.write("‚Ä¢", s)
